import os

from dotenv import load_dotenv
from langchain.chains import RetrievalQA
from langchain_community.document_loaders import TextLoader
from langchain_community.vectorstores import Chroma
from langchain_openai import ChatOpenAI, OpenAIEmbeddings

# .env èª­ã¿è¾¼ã¿
load_dotenv()
openai_api_key = os.getenv("OPENAI_API_KEY")

# 1. ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’ãƒ­ãƒ¼ãƒ‰
loader = TextLoader("documents/example.txt", encoding="utf-8")
documents = loader.load()

# 2. åŸ‹ã‚è¾¼ã¿ãƒ¢ãƒ‡ãƒ«ã¨ãƒ™ã‚¯ãƒˆãƒ«ã‚¹ãƒˆã‚¢ã‚’æ§‹ç¯‰
embeddings = OpenAIEmbeddings(openai_api_key=openai_api_key)
vectordb = Chroma.from_documents(documents, embedding=embeddings)

# 3. ãƒãƒ£ãƒƒãƒˆãƒ¢ãƒ‡ãƒ«ã¨RAGãƒã‚§ãƒ¼ãƒ³
llm = ChatOpenAI(model="gpt-4.1-nano", temperature=0, openai_api_key=openai_api_key)
qa_chain = RetrievalQA.from_chain_type(
    llm=llm,
    retriever=vectordb.as_retriever(search_kwargs={"k": 3}),
    return_source_documents=True,
)

# 4. è³ªå•
query = "ã“ã®æ–‡æ›¸ã®ä¸»ãªãƒã‚¤ãƒ³ãƒˆã¯ä½•ã§ã™ã‹ï¼Ÿ"
result = qa_chain.invoke(query)

# 5. çµæœè¡¨ç¤º
print("ğŸ§  å›ç­”:", result["result"])
print("ğŸ“„ ä½¿ç”¨ã•ã‚ŒãŸæ–‡æ›¸:")
for doc in result["source_documents"]:
    print("-", doc.metadata["source"])
